{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df58387b-c9e7-49d8-9eda-e5a3ac54b27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in c:\\users\\yashswi shukla\\appdata\\roaming\\python\\python38\\site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\yashswi shukla\\appdata\\roaming\\python\\python38\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\yashswi shukla\\appdata\\roaming\\python\\python38\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98dd735-819c-42a8-80b8-0819785e5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36cd992-b131-45f0-a1c6-03a7e89d71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: certifi in c:\\programdata\\miniconda3\\envs\\tensorflow_env\\lib\\site-packages (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install certifi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1672fa7c-0967-4199-bbd2-29d0203cce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "\n",
    "# Force Python to use certifi's CA bundle\n",
    "ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d7fec4-b971-4712-9b99-7adf7dd89427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post: It's a genuine question.\n",
      "\n",
      "    Comment 1: At least for the PS5 Pro, WHY it exists is a relatively easy question to answer... Right?\n",
      "\n",
      "WHY it exists specifically at THAT price though... Now that's the big question for Sony.\n",
      "\n",
      "    Comment 2: >But why?\n",
      "\n",
      "Because money.\n",
      "\n",
      "    Comment 3: Why iphone 16 when you can wait another year and get iphone 17?\n",
      "\n",
      "    Comment 4: It‚Äôs a filler episode year\n",
      "\n",
      "    Comment 5: \"We need your money, so I give you the same shit with slightly different but give me your money\"\n",
      "\n",
      "![gif](giphy|US86v9dnLweSaEQbq1|downsized)\n",
      "\n",
      "    Comment 6: The iPhone 16 is just the yearly iPhone model, it exists as an incremental improvement over last year.\n",
      "\n",
      "The PS5 Pro exists because money.\n",
      "\n",
      "    Comment 7: ![gif](giphy|s239QJIh56sRW|downsized)\n",
      "\n",
      "    Comment 8: Some diehard wanna-be rich technophobe kid :\n",
      "\n",
      "![gif](giphy|am0dKpQO1vrOC3DmCb|downsized)\n",
      "\n",
      "    Comment 9: Who‚Äôs the guy in the meme?\n",
      "\n",
      "    Comment 10: People used to create great things and the selling point was that they'd last for a very very long time. Then companies got greedy, wanting constant growth/profits rather than just thriving - what generates more profit than a new product? What makes people buy new products? \n",
      "\n",
      "When the old one breaks or becomes outdated. Doesn't matter how it breaks or if it's outdated/obsolete because of some pointless new feature in the new one.\n",
      "\n",
      "    Comment 11: ‚Ä¶ since IPhone 6 i always buy refurbed ones. Now i have a iPhone 12 since 3 years ‚Ä¶ those dudes and dudets are my slaves for buying those new expensive iPhones Which someday i get to choose cheaper\n",
      "\n",
      "    Comment 12: ![gif](giphy|3oxOCcdtUXYZIcgdnW)\n",
      "\n",
      "    Comment 13: Indeed 2024 is a year full of surprises!\n",
      "\n",
      "    Comment 14: Money.\n",
      "\n",
      "    Comment 15: money.\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "Post: Indonesia bans Apple iPhone 16 in the country; calls phone's use illegal in the country\n",
      "\n",
      "    Comment 1: Short version - The ban stems from Apple‚Äôs unfulfilled investment commitments in Indonesia. A few million $ in shortfall, which is chump change for Apple. \n",
      "\n",
      "Expect this one to get resolved very soon.\n",
      "\n",
      "    Comment 2: I was going to say someone did not get the proper bribe\n",
      "\n",
      "    Comment 3: What they gonna ban next - Cheetos?\n",
      "\n",
      "    Comment 4: Singapore might be happy to sell phones to touring Indonesians who would dare to illegally import them thereafter. As well as internal grey market dealers.  \n",
      "Can predict demand for camouflage cases both to mimicry v16 to another model and vice versa which might even become trendy.\n",
      "\n",
      "    Comment 5: Ppl with money will just have them imported\n",
      "\n",
      "    Comment 6: Pay up, Tim.\n",
      "\n",
      "    Comment 7: Price of iPhone 15‚Äôs just shot up\n",
      "\n",
      "    Comment 8: [deleted]\n",
      "\n",
      "    Comment 9: Every developing country trying to hold Apple hostage for \"% contents made in their country\".\n",
      "\n",
      "Only China and India is big enough of a market for Apple to do so. Indonesia is simply not even in the same weight class to be swinging their demands around.\n",
      "\n",
      "    Comment 10: Good if only China had followed\n",
      "\n",
      "    Comment 11: \"The US government announces a ban of Indomie products in retaliation.\"\n",
      "\n",
      "    Comment 12: The amount is so small to Apple. Their net operating cash flow is something like 120 billion, and they've let their flagship product be banned in a country of 270 million people, and all the negative press, and the public perception of them, all just by not paying out 15M.\n",
      "\n",
      "I can't believe this is deliberate, so I wonder what really happened.\n",
      "\n",
      "    Comment 13: Feudalism is still the mentality in this country, i can tell you that, and it's being practiced by its public officials\n",
      "\n",
      "    Comment 14: I love how people think Indonesia is terrorist and islamist. Lol\n",
      "\n",
      "    Comment 15: Pay your protection money Apple, jesh.\n",
      "\n",
      "/s\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "Post: Switched from iPhone16 to s25Ultra.\n",
      "\n",
      "    Comment 1: ![gif](giphy|Ae7SI3LoPYj8Q)\n",
      "\n",
      "    Comment 2: I ditched Apple last year.Good choice!\n",
      "\n",
      "    Comment 3: i just switched from iPhone and i'm so obsessed with this phone! the only downside is having to log into all your accounts again. anyone thinking of switching i say do it!! this phone feels so fast, it looks and feels incredible, and i'm pleasantly surprised by the battery life. i had the s22 ultra and the battery was abysmal on that phone and that's why I went back to apple for a while.\n",
      "\n",
      "    Comment 4: Welcome home\n",
      "\n",
      "    Comment 5: I am switching tomorrow‚Ä¶so excited\n",
      "\n",
      "    Comment 6: Welcome to Android üôÇüò∏\n",
      "\n",
      "    Comment 7: Welcome to the other side, where you can actually control your experience.\n",
      "\n",
      "I switched from Apple to Samsung in....2012!  Went from an iPhone 3G to a Galaxy S3.  I definitely never looked back.  Since then, I've gone to a S7 edge, then a S10+, and now a S23 Ultra.\n",
      "\n",
      "It is a family thing too.  My spouse went from a S4, to S7 edge, to S20 Ultra, and yesterday received a S25 Ultra.  My child is on their first phone, a S23+.\n",
      "\n",
      "Wait until you get into the rest of the ecosystem.  Add in two tablets (S5e & S10 light), two watches (both Watch6), and a couple of sets of earbuds (original Buds and a set of Buds+).\n",
      "\n",
      "Hmm, maybe I have a problem.\n",
      "\n",
      "    Comment 8: Have you gotten back into all your accounts, MFA recognized you, etc.? \n",
      "\n",
      "I‚Äôm just afraid of getting locked out of everything digital.\n",
      "\n",
      "    Comment 9: Welcome\n",
      "\n",
      "    Comment 10: Considering doing this what made you pull the trigger?\n",
      "\n",
      "    Comment 11: I was seriously considering switching from the 16 Pro the S25 Ultra through AT&T Next Up Anytime, but they don't carry the 1tb model and Samsung is only offering $550 for trading in the 16 Pro on their site so I decided I'll wait till next year. No brand loyalty here, I switch from Apple to Samsung every now and then, but really miss my Windows phone from back in the day...\n",
      "\n",
      "    Comment 12: Just ordered mines in black today! Patiently waiting to ditch this iPhone 15PM\n",
      "\n",
      "    Comment 13: I switched from 16 Pro Max to S24 Ultra. I love it!\n",
      "\n",
      "    Comment 14: Just ditched my iPhone a week ago. I should've done this a long time ago!!\n",
      "\n",
      "    Comment 15: I came from the 14 pro max myself. Zero regrets. Welcome to the club!\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "Post: It's a genuine question.\n",
      "\n",
      "    Comment 1: >But why?\n",
      "\n",
      "Because money.\n",
      "\n",
      "    Comment 2: The only console I ever bought after my first salary was Nintendo Switch. \n",
      "\n",
      "Played so much out of it and I can say it was worth it and it was only 250‚Ç¨. \n",
      "\n",
      "Now I don't think I will buy anything except build my own PC.\n",
      "\n",
      "    Comment 3: Cuz some dumb ppl will buy them , alot of dumb ppl\n",
      "\n",
      "    Comment 4: ![gif](giphy|xUPGGw7jxnwjk073sA)\n",
      "\n",
      "    Comment 5: Does this mean the normal ps5 becomes cheaper?\n",
      "\n",
      "![gif](giphy|STfLOU6iRBRunMciZv)\n",
      "\n",
      "    Comment 6: But still they are going to sell very well, and I don‚Äôt know how. Who ? Who buys these ?\n",
      "\n",
      "    Comment 7: [removed]\n",
      "\n",
      "    Comment 8: Ps6 is around the corner though ps5 just came out like yesterday tbf\n",
      "\n",
      "    Comment 9: Well. When you're full of passion of something. You know what's good, what's not.\n",
      "\n",
      "Your friend who doesn't play video games or doesn't care about technology, will buy what his coworkers tell him or the advertising show him.\n",
      "\n",
      "    Comment 10: So you can finally consider getting a pc\n",
      "\n",
      "    Comment 11: Images you can hear\n",
      "\n",
      "    Comment 12: Because you buy it.\n",
      "\n",
      "    Comment 13: We need to buy lots of both of them...won't someone please think of executive bonuses and infinite shareholder value growth!!!!  Take out a 2nd or 3rd mortgage if you have to, cash in your retirement savings, and run up credit card debit on the ultra high interest rate credit card, but please do everything you possibly can to help those more fortunate than you to increase their wealth!\n",
      "\n",
      "/s\n",
      "\n",
      "    Comment 14: Lol, the PS5 Pro is $700 too.\n",
      "\n",
      "    Comment 15: ![gif](giphy|s239QJIh56sRW|downsized)\n",
      "\n",
      "smh op used the wrong but why\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n",
      "Post: Cracking Morgan Stanley as a 2 YoE developer from tier 3 college (full experience)\n",
      "\n",
      "    Comment 1: >Namaste!\n",
      "Thanks for submitting to r/developersIndia. While participating in this thread, please follow the Community [Code of Conduct](https://developersindia.in/code-of-conduct/) and [rules](https://www.reddit.com/r/developersIndia/about/rules).\n",
      " \n",
      "It's possible your query is not unique, use [`site:reddit.com/r/developersindia KEYWORDS`](https://www.google.com/search?q=site%3Areddit.com%2Fr%2Fdevelopersindia+%22YOUR+QUERY%22&sca_esv=c839f9702c677c11&sca_upv=1&ei=RhKmZpTSC829seMP85mj4Ac&ved=0ahUKEwiUjd7iuMmHAxXNXmwGHfPMCHwQ4dUDCBA&uact=5&oq=site%3Areddit.com%2Fr%2Fdevelopersindia+%22YOUR+QUERY%22&gs_lp=Egxnd3Mtd2l6LXNlcnAiLnNpdGU6cmVkZGl0LmNvbS9yL2RldmVsb3BlcnNpbmRpYSAiWU9VUiBRVUVSWSJI5AFQAFgAcAF4AJABAJgBAKABAKoBALgBA8gBAJgCAKACAJgDAIgGAZIHAKAHAA&sclient=gws-wiz-serp) on search engines to search posts from developersIndia. You can also use [reddit search](https://www.reddit.com/r/developersIndia/search/) directly.\n",
      "\n",
      "## Recent Announcements & Mega-threads\n",
      "\n",
      "- **[The developersIndia Wiki Team needs your help! Share posts & comments that have helped you in the past.](https://www.reddit.com/r/developersIndia/comments/1gbtbdn/the_developersindia_wiki_team_needs_your_help/)**\n",
      "- **[Who's looking for work? - Monthly Megathread - November 2024](https://www.reddit.com/r/developersIndia/comments/1ggxjkg/whos_looking_for_work_monthly_megathread_november/)**\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/developersIndia) if you have any questions or concerns.*\n",
      "\n",
      "    Comment 2: God damn, 7 months to get a job.....you have some serious patience my guy.\n",
      "\n",
      "    Comment 3: The duckers had the audacity of lowballing you to 14 LPA earlier after they made you go through so much\n",
      "\n",
      "    Comment 4: Now  I know why people are preparing govt exam all their lives. Lol . That is much easier.\n",
      "\n",
      "    Comment 5: Reading all this felt so overwhelming...\n",
      "\n",
      "    Comment 6: OP, thanks for such a comprehensive account of your experience! I'm sure this would be of great use to most new grads. \n",
      "\n",
      "Honestly, if you ask me, this seems a bit too exhausting, especially for an Associate SDE. I feel like they were trying to squeeze you as much as possible, see if you'd crack, and finally offer you the least they can. 19 base feels like a drop in the ocean compared to the intensity of their interviews tbh, I guess that's the standard payout for 2 YoE. \n",
      "\n",
      "Regardless, you seem smart, I'm pretty sure you'd leverage this salary for your next jump! All the best!\n",
      "\n",
      "    Comment 7: # If this is all for a 2 YOE‚Äôd candidate how‚Äôs it gonna be for 10 years ?\n",
      "\n",
      "    Comment 8: Hey, I am currently an intern at Morgan - Stanley itself. Would it be ok if we connect something?\n",
      "\n",
      "    Comment 9: Thanks for sharing the process.\n",
      "\n",
      "    Comment 10: Thanks, this will be helpful for others.\n",
      "\n",
      "    Comment 11: Thanks for sharing OP! It would've helped more if you could share the preparation strategies you used.\n",
      "\n",
      "    Comment 12: Have you resigned already?\n",
      "Do you resign before or after background verification\n",
      "\n",
      "    Comment 13: Just read you tech stack OPüò¶, how‚Äôd you learnn itt alll in just a couple of yearsss. An inspiration manü´°.\n",
      "If you could share some reliable resources for a beginner-intermediate like me will benefit a lott.If not here, I can dm youuu Thanks OP.\n",
      "\n",
      "    Comment 14: Which is more prestigious: Cracking Morgan Stanley or rejecting them? I rejected their offer because they were trying to lowball me.\n",
      "\n",
      "    Comment 15: Bhai ye sab kya hai :((( idk how am gonna survive after graduating\n",
      "\n",
      "\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Create a Reddit instance (Replace with your credentials)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"5XxI8AdauHxoDN8kgzck3w\",\n",
    "    client_secret=\"Y0PscnV3y40Kpz2kusRgnUPpB42Nww\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Function to fetch top posts and their top comments\n",
    "def fetch_top_posts_with_comments(search_query, subreddit_name='all', post_limit=5, comment_limit=15):\n",
    "    try:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        top_posts = subreddit.search(search_query, sort='top', limit=post_limit)\n",
    "\n",
    "        for post in top_posts:\n",
    "            print(f\"Post: {post.title}\\n\")\n",
    "            \n",
    "            # Fetch top comments\n",
    "            post.comments.replace_more(limit=0)  # Load all comments\n",
    "            top_comments = [comment.body for comment in post.comments.list()[:comment_limit]]\n",
    "            \n",
    "            for i, comment in enumerate(top_comments, 1):\n",
    "                print(f\"    Comment {i}: {comment}\\n\")\n",
    "            print(\"\\n------------------------\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching posts and comments: {e}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    search_query = input(\"Enter the topic you want to search for: \")\n",
    "    subreddit_name = input(\"Enter the subreddit to search in (default is 'all'): \") or 'all'\n",
    "    fetch_top_posts_with_comments(search_query, subreddit_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f31a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb67cf75-0290-4f35-8fa7-fccd8bee25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_posts.json\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import json\n",
    "\n",
    "# Create a Reddit instance (Replace with your credentials)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Function to fetch top posts and their top comments\n",
    "def fetch_top_posts_with_comments(search_query, subreddit_name='all', post_limit=5, comment_limit=15):\n",
    "    data = []  # List to store post data\n",
    "    try:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        top_posts = subreddit.search(search_query, sort='top', limit=post_limit)\n",
    "\n",
    "        for post in top_posts:\n",
    "            post_data = {\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": []\n",
    "            }\n",
    "            \n",
    "            # Fetch top comments\n",
    "            post.comments.replace_more(limit=0)  # Load all comments\n",
    "            top_comments = [comment.body for comment in post.comments.list()[:comment_limit]]\n",
    "            \n",
    "            post_data[\"comments\"].extend(top_comments)\n",
    "            data.append(post_data)\n",
    "        \n",
    "        # Save data to a JSON file\n",
    "        with open(\"reddit_posts.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(\"Data saved to reddit_posts.json\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching posts and comments: {e}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    search_query = input(\"Enter the topic you want to search for: \")\n",
    "    subreddit_name = input(\"Enter the subreddit to search in (default is 'all'): \") or 'all'\n",
    "    fetch_top_posts_with_comments(search_query, subreddit_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cb676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a03fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19eb7161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Spacy model not found. Using basic regex-based optimization.\n",
      "\n",
      "üîç Searching in subreddit: r/BudgetGamingLaptop for 'budget gaming laptop'\n",
      "\n",
      "\n",
      "üîπ 1. HOW IS THIS DEAL FOR A BUDGET GAMING LAPTOP?\n",
      "üîó URL: https://www.reddit.com/gallery/1ic181d\n",
      "üí¨ Top Comments:\n",
      "   - In Ca$ or Us$? In cad maybe but in usd NO!! I saw a RTX 4070m laptop for just 999 and with a far newer cpu\n",
      "   - https://gaminglaptop.deals\n",
      "\n",
      "üîπ 2. Best Gaming Laptops in 2024/2025 List.\n",
      "üîó URL: https://www.reddit.com/r/BudgetGamingLaptop/comments/1emetuz/best_gaming_laptops_in_20242025_list/\n",
      "üí¨ Top Comments:\n",
      "   - [removed]\n",
      "   - [removed]\n",
      "   - Thanks for putting so much effort making this post. Definitely worth looking at it.\n",
      "\n",
      "BTW, I use Predator and it's the best gaming laptop according to me, absolute beast.\n",
      "   - I just picked up the Lenovo Legion 5 Pro with the AMD processor, and it‚Äôs a beast. It ticks all your boxes, but if you plan to game on it, you‚Äôll likely need the power adapter. This is true for most gaming laptops.\n",
      "   - The best choice for a gaming laptop is the HP OMEN 17-ck1023TX. It‚Äôs a powerful machine featuring a 12th Gen Intel Core i9 processor, NVIDIA GeForce RTX 3080 Ti GPU, 32GB of DDR5-4800MHz RAM, and a 2TB PCIe NVMe SSD. The QHD IPS antiglare display is Eyesafe certified to reduce eye strain during long gaming sessions. The RGB 4-zone anti-ghosting keyboard is a nice touch for gaming enthusiasts. For more information on gaming laptops, check out the GamesGear section of PCQuest and the CIOL section of the NextGenIT website.\n",
      "\n",
      "üîπ 3. Best budget gaming laptop in 2025 according to reddit?\n",
      "üîó URL: https://www.reddit.com/r/BudgetGamingLaptop/comments/1htmma6/best_budget_gaming_laptop_in_2025_according_to/\n",
      "üí¨ Top Comments:\n",
      "   - Here‚Äôs something to keep in mind about gaming laptops if you‚Äôre new to them:  \n",
      "\n",
      "- They‚Äôll never be as powerful as a comparable desktop PC.  \n",
      "- They won‚Äôt last as long as a desktop PC in terms of performance and durability.  \n",
      "- Their thermals are worse compared to desktops, meaning they can heat up a lot more.  \n",
      "\n",
      "So, make sure mobility is your priority. If you‚Äôre only going to use it in one room, you‚Äôre better off with a desktop.  \n",
      "\n",
      "Also, gaming laptops only perform at their best when plugged into a power socket. On battery mode, they significantly reduce power to extend battery life. If you force them to run at full performance on battery, the charge will drain incredibly fast.\n",
      "   - I recently updated my [Group Test](https://smbtech.au/features/best-gaming-laptops/) and noticed that gaming laptop specs really haven't changed much since 2023. You can get older premium models with 4070s, 4080s and 4090s for much less just because they've got 13th-gen processors. However, right now, the [Acer Nitro V 16](https://smbtech.au/features/acer-nitro-v-16-laptop-review/) is the best (because it's on sale where I am).\n",
      "\n",
      "üîπ 4. Budget gaming laptop with a price around max price 800$(Canadian)\n",
      "üîó URL: https://www.reddit.com/r/BudgetGamingLaptop/comments/1i8itm9/budget_gaming_laptop_with_a_price_around_max/\n",
      "üí¨ Top Comments:\n",
      "\n",
      "üîπ 5. Most reliable gaming laptop under 1000 dollars\n",
      "üîó URL: https://www.reddit.com/r/BudgetGamingLaptop/comments/1gkx24m/most_reliable_gaming_laptop_under_1000_dollars/\n",
      "üí¨ Top Comments:\n",
      "   - Why are you upset?\n",
      "   - [removed]\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import requests\n",
    "import spacy\n",
    "import re\n",
    "import ssl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Try to load Spacy model, use a fallback method if it fails\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"[WARNING] Spacy model not found. Using basic regex-based optimization.\")\n",
    "    nlp = None\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Fix SSL Issue\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Step 1: Optimize the query\n",
    "def optimize_query(query):\n",
    "    \"\"\"Optimizes user query using NLP or regex-based keyword extraction.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return \" \".join(keywords)\n",
    "    else:\n",
    "        # Fallback if Spacy is not installed\n",
    "        query = query.lower()\n",
    "        query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", query)  # Remove special characters\n",
    "        keywords = query.split()  # Basic word split\n",
    "        return \" \".join(keywords)\n",
    "\n",
    "# Step 2: Find the most relevant subreddit\n",
    "def find_best_subreddit(query):\n",
    "    \"\"\"Finds the most relevant subreddit based on a given query.\"\"\"\n",
    "    search_url = f\"https://www.reddit.com/search/?q={query}&type=sr\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        subreddit_links = soup.find_all('a', href=True)\n",
    "\n",
    "        for link in subreddit_links:\n",
    "            href = link['href']\n",
    "            if '/r/' in href and not href.startswith(\"https://www.reddit.com/user/\"):\n",
    "                return href.split('/r/')[1].split('/')[0]  # Extract subreddit name\n",
    "    return \"all\"  # Default to r/all if no specific subreddit is found\n",
    "\n",
    "# Step 3: Fetch posts from the best subreddit\n",
    "def fetch_reddit_posts(query):\n",
    "    \"\"\"Fetches top posts from the best subreddit for the query.\"\"\"\n",
    "    optimized_query = optimize_query(query)\n",
    "    best_subreddit = find_best_subreddit(optimized_query)\n",
    "    \n",
    "    print(f\"\\nüîç Searching in subreddit: r/{best_subreddit} for '{optimized_query}'\\n\")\n",
    "    \n",
    "    try:\n",
    "        subreddit = reddit.subreddit(best_subreddit)\n",
    "        top_posts = subreddit.search(optimized_query, limit=5)\n",
    "\n",
    "        results = []\n",
    "        for post in top_posts:\n",
    "            results.append({\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": [comment.body for comment in post.comments[:5]]\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching posts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Get user query and display results\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    posts = fetch_reddit_posts(user_query)\n",
    "\n",
    "    if posts:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nüîπ {idx+1}. {post['title']}\")\n",
    "            print(f\"üîó URL: {post['url']}\")\n",
    "            print(\"üí¨ Top Comments:\")\n",
    "            for comment in post['comments']:\n",
    "                print(f\"   - {comment}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No relevant posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b292cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful: True\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Initialize Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Test if authentication works\n",
    "print(\"Authentication successful:\", reddit.read_only)  # Should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a7391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66c175df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Spacy model not found. Using basic regex-based optimization.\n",
      "\n",
      "üîç Searching in subreddit: r/BudgetAudiophile for 'best gaming budget'\n",
      "\n",
      "‚úÖ Data saved to reddit_results.json\n",
      "\n",
      "üîπ 1. Best budget speakers against the wall\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1ih26b3/best_budget_speakers_against_the_wall/\n",
      "üí¨ Top Comments:\n",
      "   - If you want them directly against the wall or maybe a few centimeters away, the only requirement is that they're not rear ported, as that would require merely a few inches, but not less.  Beyond that port spacing requirement, all speakers work best as as close to the wall as possible, but simply need EQ to tailor the bass response.  So buy whatever speakers you want based on the other factors you value or strengths they have, but you must implement a way of using parametric EQ, either from a PC, or miniDSP, or a source that has custom EQ ability or competent room correction.\n",
      "   - You should look for front or downward ported speakers.   But even with these it would help to be at least 8\" away.  But if you can't, you can always place cheap acoustic panels behind the speakers to prevent harsh reflections from being so close.  I did this with my Elac UBR 62s that were to close to the back and side walls in my bedroom office and it really cut down on the harsh treble.   They work because they have an NRC of 95% (but only work on upper mids and treble).  Here's a picture of them\n",
      "\n",
      "https://preview.redd.it/dhm65xc9p2he1.jpeg?width=1632&format=pjpg&auto=webp&s=ed664f160f875b8ce5aa0384333da8788949e40c\n",
      "\n",
      "Purchased here: [https://www.amazon.com/dp/B0CC1VLHMB?ref\\_=ppx\\_hzsearch\\_conn\\_dt\\_b\\_fed\\_asin\\_title\\_1](https://www.amazon.com/dp/B0CC1VLHMB?ref_=ppx_hzsearch_conn_dt_b_fed_asin_title_1)\n",
      "   - Polk ES20\n",
      "   - NHT Superone 2.1\n",
      "   - Ohm Walsh, if you can find any used nearby.\n",
      "\n",
      "üîπ 2. Looking for the BEST speaker or soundbar for PC gaming purpose (movie and song sometime but not often) that FITs my limited space. No budget limit. I am considering Razer but heard it sucks. Is it real?\n",
      "üîó URL: https://i.redd.it/230dknimjw9e1.jpeg\n",
      "üí¨ Top Comments:\n",
      "   - If budget truely isn't an issue, i would move the pc somewhere else because why are you only using 40% of your table\n",
      "   - If you put that abomination under the desk where it belongs, you'll have plenty of space for proper speakers.\n",
      "   - dude send that case back to temu\n",
      "   - Put that monstrosity under the desk, should fix the space issue.\n",
      "   - Rule of thumb. Soundbars are generally considered a shitty solution to audio problems. I ran into this when I purchased my speakers. I thought a soundbar would be worthwhile but the price didn't validate the performance.  \n",
      "  \n",
      "**You can get better sound quality from speakers of the same price than if you spent it all on a soundbar.**\n",
      "\n",
      "Your setup is tight fitting but if you went with something like the[ Edifier G2000s](https://www.amazon.com/Edifier-Computer-Bluetooth-Multimedia-subwoofer/dp/B00UAFSN5O/ref=asc_df_B00UAFSN5O?mcid=2386c508394332a687d1d2b20ee48b89&hvocijid=16521915450812727398-B00UAFSN5O-&hvexpln=73&tag=hyprod-20&linkCode=df0&hvadid=692875362841&hvpos=&hvnetw=g&hvrand=16521915450812727398&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9004151&hvtargid=pla-2281435179738&th=1), you could squeeze a decent pair of speakers into that mix. They aren't large but the sound is pretty great for the price. They're conventional desktop speakers designed for gaming.\n",
      "\n",
      "You go a little higher in price and you can get something like the [Mackie CR2-Xs](https://www.amazon.com/Mackie-Premium-Speakers-CR2-X-Cube/dp/B0BFYBLJ9Y/ref=asc_df_B0BFYBLJ9Y?mcid=76900174d32a3ab5a4b5168e2dcbefb2&hvocijid=1165999673874057772-B0BFYBLJ9Y-&hvexpln=73&tag=hyprod-20&linkCode=df0&hvadid=721245378154&hvpos=&hvnetw=g&hvrand=1165999673874057772&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9004151&hvtargid=pla-2281435178058&psc=1) which fit the same niche as the prior. \n",
      "\n",
      "These are not enormous speakers so they should be workable in your setup and the sound you get will likely be above and beyond a conventional soundbar solution.\n",
      "\n",
      "üîπ 3. Help Choosing Gaming PC with $250 Budget Speakers\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1ikd6h3/help_choosing_gaming_pc_with_250_budget_speakers/\n",
      "üí¨ Top Comments:\n",
      "   - Would Fluance Ai41 be too large?\n",
      "\n",
      "Best bang for your budget would be second hand. An older AV receiver with some bookshelf speakers is more than doable on you budget.   \n",
      "Downside is that it will take up more space, but its worth it. It will be a proper hi-fi system.\n",
      "   - Get the promedia heritage 2.1. It's the update to the promedia 2.1.\n",
      "\n",
      "  \n",
      "Here's a review: [https://youtu.be/-EzmCn7oEGs?si=6LAtWAJfMnCJGgM2](https://youtu.be/-EzmCn7oEGs?si=6LAtWAJfMnCJGgM2)\n",
      "\n",
      "üîπ 4. Best 2.0/2.1 speakers for gaming? (100-150$)\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1ghb4sm/best_2021_speakers_for_gaming_100150/\n",
      "üí¨ Top Comments:\n",
      "   - Edifier MR4.\n",
      "   - The combo 2.1 units are bad for a few reasons, but chief among them is the tri amped subwoofer enclosure. If a normal sub blows, you can replace it, not so with these.\n",
      "\n",
      "A good subwoofer is going to set you back $200+ by itself new. Instead of a 2.1 setup, buy good speakers with an RCA / sub out, and then when money allows purchase a used powered subwoofer that is at-least 200w peak. Audioengine A1/A2 would be a good choice for the speakers.\n",
      "   - In my opinion if it‚Äôs strictly for gaming only I would just stick to upgrading a better gaming headset.  You can‚Äôt really get immersive experience with only 2 speakers.  If you‚Äôre into FPS gaming, rear channels are very crucial in playing for your performance.\n",
      "\n",
      "üîπ 5. Best Budget speakers for a desktop system? \n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1i4ugsz/best_budget_speakers_for_a_desktop_system/\n",
      "üí¨ Top Comments:\n",
      "   - The 1st set\n",
      "\n",
      "üîπ 6. Best gaming / all purposes speakers? Budget friendly / high quality all in one setup in minalimal space with minimal external devices/wires/connections and must work with TV/PC/Consoles all together with a single connection and supporting surround/Dolby/DTS?\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1gawj6p/best_gaming_all_purposes_speakers_budget_friendly/\n",
      "üí¨ Top Comments:\n",
      "   - Far too many questions, and your level of ignorance is so extreme that it would not be easy to answer them because of the sheer amount of background or foundational knowledge that would have to be expressed; you need an entire book it seems.\n",
      "\n",
      "How about instead you don't worry about ANY of that.  You're describing one of the simplest setups there is.  You could do this with one HDMI cable or optical cable from the TV to your system.  This isn't the way I would do it but you can.  This assumes you're using the TV for a PC monitor.  If you're not, then you'll need 2 connections.  Just use the optical output from the PC, and the HDMI from the TV in that case.  Yes you could also use the GPU HDMI out, if you have enough HDMI inputs.  The reason HDMI can transmit audio is because it's just digital, your old soundcard had a DAC, turning that into an analog signal.\n",
      "\n",
      "You only need one thing, and I recommend this due to its simplicity and relatively high audio quality, but it's not the cheapest solution possible.  Get the Klipsch \"Sevens\" or \"Nines\", not the Fives they're too small and lame, but if you can swing one of the two bigger models, it'll be great and super simple for you.  Really any powered speakers with multiple inputs and a remote will work.\n",
      "   - If you want good quality surround sound from your PC, get an AVR and passive speakers. Your PC connects to the AVR using an HDMI cable. Then, the AVR to the TV with another HDMI cable.\n",
      "\n",
      "All of my PC's have passive speakers powered by AVRs. I have a 5.1 system hooked to my HTPC, a 2.1 system on my main machine, and a 3.0/5.0 system in the bedroom.\n",
      "\n",
      "Along with getting the speakers, AVR, and cables, there's also some software setting you have to configure. It's not to hard to do.\n",
      "\n",
      "üîπ 7. Best Powered 2.1 setup for PC use? Gaming, general use, music (rock/metal)? Prioritizing midbass punch. Ideally around $500, up to $2k.\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1hrvv8d/best_powered_21_setup_for_pc_use_gaming_general/\n",
      "üí¨ Top Comments:\n",
      "   - Kali LP-UNF. They're made for near-field usage, but your end-game would probably be something like a Genelec 8030C if you want pretty much the best active, fire-and-forget setup. They are usually quoted per speaker, not pair.\n",
      "\n",
      "üîπ 8. Harman Kardon soundsticks 2 just died after 10 years, best budget replacement? \n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1gwrene/harman_kardon_soundsticks_2_just_died_after_10/\n",
      "üí¨ Top Comments:\n",
      "   - You could possibly get iLoud Micro Monitors, Adam Audio D3V or Kali LP-UNF under ‚Ç¨¬£300 now under black friday/week. \n",
      "\n",
      "Edifier MR4 under ‚Ç¨¬£200. \n",
      "\n",
      "Second hand if you are in the UK. Such a great second hand market, it would be foolish to buy new.\n",
      "\n",
      "üîπ 9. Best speakers for PC gaming? (~$400 budget)\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1ete00o/best_speakers_for_pc_gaming_400_budget/\n",
      "üí¨ Top Comments:\n",
      "   - Make sure you measure the speakers before you buy them so they fit on your desk. Do not put speakers against the wall also there are cables sticking out.\n",
      "\n",
      "For that price i would recommend the \"Triangle Active Series - LN01A\" speakers for good sound and they are not to big.\n",
      "\n",
      "* Triangle BR02 CONNECT \n",
      "* Argon FORTE A4 MK2\n",
      "* Peachtree M25X \n",
      "* Kanto YU6 Powered Bookshelf Speakers\n",
      "* Q Acoustics M20 HD\n",
      "* Triangle Active Series - LN01A\n",
      "* Argon FENRIS A5\n",
      "* Argon FENRIS A4\n",
      "   - Someone else just posted The Fives by Klipsch were marked down to $400 on Amazon right now. \n",
      "\n",
      "I had been using The Sixes as desktop speakers for a while and enjoyed them. I stopped using them only because I got a bigger display and there wasn't enough room on my desk anymore.\n",
      "   - A sub will make a huge difference with speakers of this size, there really isnt any comparison. Id make sure that you buy a set with an output. There are wireless subwoofer kits if the wires are really a problem.\n",
      "\n",
      "Can‚Äôt go wrong with the A2, I have the Audioengine HD3 on my desk at work and really enjoy them. Ive seen the A2s on ebay for $140.\n",
      "   - I personally really enjoy my Micca RB42 speakers for use with my PC on my desk. They're 8.7\" tall and I have my monitors above them on monitor arms. Not everyone likes monitors that high though, so if you want them below monitors, consider height.\n",
      "\n",
      "I run then with a dual chip TPA3116 amp and find them very satisfying without a sub. Plenty of budget for whatever amp you might want to pair them with.\n",
      "\n",
      "Here's an old post with some pics of my setup: https://www.reddit.com/r/BudgetAudiophile/comments/vdeep6/just_got_a_couple_of_rb42s_set_up_for_my_little/\n",
      "   - I wouldnt be afraid of studio monitors. There is a lot of myths and misconceptions about them going around. \n",
      "\n",
      "A lot of the speakers you are looking at are neutral speakers, just like studio monitors.   \n",
      "This is also what studies show what most people think sounds the best.\n",
      "\n",
      "üîπ 10. Best Budget Desktop Speakers?\n",
      "üîó URL: https://www.reddit.com/r/BudgetAudiophile/comments/1cs555w/best_budget_desktop_speakers/\n",
      "üí¨ Top Comments:\n",
      "   - I have the Edifier R1280DBs and I really like them. I will say I thought they were just fine UNTIL I paired them with a subwoofer. I felt like it made a major change to their sound quality and it suddenly felt less tinny.\n",
      "   - Check out the Creative Stage SE. It's currently ¬£40 on Amazon.\n",
      "   - I had those Edifiers for a year or so. Excellent for the price.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import requests\n",
    "import spacy\n",
    "import re\n",
    "import ssl\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Try to load Spacy model, use a fallback method if it fails\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"[WARNING] Spacy model not found. Using basic regex-based optimization.\")\n",
    "    nlp = None\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Fix SSL Issue\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Step 1: Optimize the query\n",
    "def optimize_query(query):\n",
    "    \"\"\"Optimizes user query using NLP or regex-based keyword extraction.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return \" \".join(keywords)\n",
    "    else:\n",
    "        # Fallback if Spacy is not installed\n",
    "        query = query.lower()\n",
    "        query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", query)  # Remove special characters\n",
    "        keywords = query.split()  # Basic word split\n",
    "        return \" \".join(keywords)\n",
    "\n",
    "# Step 2: Find the most relevant subreddit\n",
    "def find_best_subreddit(query):\n",
    "    \"\"\"Finds the most relevant subreddit based on a given query.\"\"\"\n",
    "    search_url = f\"https://www.reddit.com/search/?q={query}&type=sr\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        subreddit_links = soup.find_all('a', href=True)\n",
    "\n",
    "        for link in subreddit_links:\n",
    "            href = link['href']\n",
    "            if '/r/' in href and not href.startswith(\"https://www.reddit.com/user/\"):\n",
    "                return href.split('/r/')[1].split('/')[0]  # Extract subreddit name\n",
    "    return \"all\"  # Default to r/all if no specific subreddit is found\n",
    "\n",
    "# Step 3: Fetch posts from the best subreddit\n",
    "def fetch_reddit_posts(query):\n",
    "    \"\"\"Fetches top 10 posts from the best subreddit for the query and stores in a JSON file.\"\"\"\n",
    "    optimized_query = optimize_query(query)\n",
    "    best_subreddit = find_best_subreddit(optimized_query)\n",
    "    \n",
    "    print(f\"\\nüîç Searching in subreddit: r/{best_subreddit} for '{optimized_query}'\\n\")\n",
    "    \n",
    "    try:\n",
    "        subreddit = reddit.subreddit(best_subreddit)\n",
    "        top_posts = subreddit.search(optimized_query, limit=10)\n",
    "\n",
    "        results = []\n",
    "        for post in top_posts:\n",
    "            post.comments.replace_more(limit=0)  # Load all top-level comments\n",
    "            comments = [comment.body for comment in post.comments[:20]]  # Get first 20 comments\n",
    "\n",
    "            results.append({\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": comments\n",
    "            })\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open(\"reddit_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(\"‚úÖ Data saved to reddit_results.json\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching posts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Get user query and display results\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    posts = fetch_reddit_posts(user_query)\n",
    "\n",
    "    if posts:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nüîπ {idx+1}. {post['title']}\")\n",
    "            print(f\"üîó URL: {post['url']}\")\n",
    "            print(\"üí¨ Top Comments:\")\n",
    "            for comment in post['comments'][:5]:  # Show only first 5 comments in the terminal\n",
    "                print(f\"   - {comment}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No relevant posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3311b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba85fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f74c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee7c911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Spacy model not found. Using basic regex-based optimization.\n",
      "\n",
      "üîç Searching in subreddit: r/RepTime for 'best gamint pc no budget'\n",
      "\n",
      "‚úÖ Data saved to reddit_results.json\n",
      "‚ö†Ô∏è No relevant posts found.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import requests\n",
    "import spacy\n",
    "import re\n",
    "import ssl\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Try to load Spacy model, use a fallback method if it fails\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"[WARNING] Spacy model not found. Using basic regex-based optimization.\")\n",
    "    nlp = None\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Fix SSL Issue\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Step 1: Optimize the query\n",
    "def optimize_query(query):\n",
    "    \"\"\"Optimizes user query using NLP or regex-based keyword extraction.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return \" \".join(keywords)\n",
    "    else:\n",
    "        # Fallback if Spacy is not installed\n",
    "        query = query.lower()\n",
    "        query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", query)  # Remove special characters\n",
    "        keywords = query.split()  # Basic word split\n",
    "        return \" \".join(keywords)\n",
    "\n",
    "# Step 2: Find the most relevant subreddit\n",
    "def find_best_subreddit(query):\n",
    "    \"\"\"Finds the most relevant subreddit based on a given query.\"\"\"\n",
    "    search_url = f\"https://www.reddit.com/search/?q={query}&type=sr\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        subreddit_links = soup.find_all('a', href=True)\n",
    "\n",
    "        for link in subreddit_links:\n",
    "            href = link['href']\n",
    "            if '/r/' in href and not href.startswith(\"https://www.reddit.com/user/\"):\n",
    "                return href.split('/r/')[1].split('/')[0]  # Extract subreddit name\n",
    "    return \"all\"  # Default to r/all if no specific subreddit is found\n",
    "\n",
    "# Step 3: Fetch posts and comments from the best subreddit\n",
    "def fetch_reddit_posts(query):\n",
    "    \"\"\"Fetches top 10 posts and first 20 comments per post from the best subreddit.\"\"\"\n",
    "    optimized_query = optimize_query(query)\n",
    "    best_subreddit = find_best_subreddit(optimized_query)\n",
    "    \n",
    "    print(f\"\\nüîç Searching in subreddit: r/{best_subreddit} for '{optimized_query}'\\n\")\n",
    "    \n",
    "    try:\n",
    "        subreddit = reddit.subreddit(best_subreddit)\n",
    "        top_posts = subreddit.search(optimized_query, limit=10)\n",
    "\n",
    "        results = []\n",
    "        for post in top_posts:\n",
    "            post.comments.replace_more(limit=0)  # Load all top-level comments\n",
    "            \n",
    "            comments = []\n",
    "            for comment in post.comments[:20]:  # Get first 20 comments\n",
    "                comments.append(comment.body)\n",
    "\n",
    "            results.append({\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": comments\n",
    "            })\n",
    "\n",
    "        # Save results to JSON file\n",
    "        with open(\"reddit_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(\"‚úÖ Data saved to reddit_results.json\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching posts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Get user query and display results\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    posts = fetch_reddit_posts(user_query)\n",
    "\n",
    "    if posts:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nüîπ {idx+1}. {post['title']}\")\n",
    "            print(f\"üîó URL: {post['url']}\")\n",
    "            print(\"üí¨ Top Comments:\")\n",
    "            for comment in post['comments'][:5]:  # Show only first 5 comments in the terminal\n",
    "                print(f\"   - {comment}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No relevant posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebcd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345894f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c804b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Spacy model not found. Using basic keyword extraction.\n",
      "\n",
      "üîç Searching in subreddit: r/gamingpc for 'best budget gaming pc'\n",
      "\n",
      "‚úÖ Data saved to reddit_results.json\n",
      "\n",
      "üîπ 1. Looking for the BEST speaker or soundbar for PC gaming purpose (movie and song sometime but not often) that FITs my limited space. No budget limit. I am considering Razer but heard it sucks. Is it real?\n",
      "üîó URL: https://www.reddit.com/gallery/1hpdibd\n",
      "üí¨ Top Comments:\n",
      "   - The simple answer  is to get your hands on some studio monitors ( speakers ). Run them through an external device  such as a focusrite solo amazing sound quality  for around 200\n",
      "   - I've tried to like Razer, but everything I buy of theirs ends up failing or their software breaks things in my system. 2 mice, one keyboard and 2 sets of Leviathan v2, so I won't be doing that again. \n",
      "\n",
      "Feedback on the Leviathan v2 though: I ran the $200-300 model for about 6 months. When it worked, it sounded great. Not as good as a full 5 or 7.1 setup, but for its size it does a decent job. At the 6 month mark though, my audio dropped in the middle of a show I was watching. I spent the next hour or two trying to figure out why it seemed to be powered on but wouldn't connect to anything. Opened a case with Razer and they wouldn't even talk to me about troubleshooting without a copy of my receipt which I did not have. I argued with them for 2 weeks and finally just took it back to Best Buy where I bought it. Grabbed the Edifier r1700 and it sounds so much better than the Razer.\n",
      "\n",
      "Good luck.\n",
      "   - Whatever is available in Facebook marketplace for a good price\n",
      "   - If you can have a sub, I'd say the Klipsch Promedia Heritage 2.1. For $285 USD it doesn't really get much better unless you spring for more expensive/powerful powered speakers or configure your own speakers/sub/amp from scratch.\n",
      "\n",
      "If you can't have a sub though, well, don't bother with those. The satellites have zero bass capability on their own as they are entirely for upper midrange and high frequencies.\n",
      "   - Klipsche. 2.1 Studio set up. They sound fucking amazing. Snagged some for $40 from an old guy who probably never turned them up past 2.\n",
      "\n",
      "üîπ 2. Best Budget Gaming PC?\n",
      "üîó URL: https://www.reddit.com/r/gamingpc/comments/1baxom0/best_budget_gaming_pc/\n",
      "üí¨ Top Comments:\n",
      "   - Hello Retail-Forever, and thank you for your submission to Gaming PC! If you are new please check out our rules over at the wiki [here](https://www.reddit.com/r/gamingpc/wiki/rules)!\n",
      "We have recently added the useful feature of Title Flair! You can set this manually by clicking Flair under your post once you have submitted your post, but if you missed it in the rules there is a much better way that will automatically flair your post!   \n",
      "\n",
      "To do this simply add what your post is about in brackets before your title. For example for a Build Log you can type [Build Log] before your post so that it looks like this; [Build Log]My new awesome build!, and the bot will automatically set your flair to Build Log! This works for Build Log, Build Showcase, News, Hardware News, Hardware Release, Discussion, and Miscellaneous!\n",
      "\n",
      "Also remember that this is a place for discussing and sharing our love of Gaming Computers! This is NOT the place for help building or determining what parts you should buy, that is better suited for /r/buildapc.  Troubleshooting questions should be directed to /r/techsupport. Thank you again!\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/gamingpc) if you have any questions or concerns.*\n",
      "\n",
      "üîπ 3. This is far from the most substantial in the world, but considering this is a largely budgeted setup after my last PC suddenly died on me last August, I'm not gonna complain much. Honestly, this may be my best gaming/editing setup to date (Specs in comments)\n",
      "üîó URL: https://www.reddit.com/gallery/q7qex6\n",
      "üí¨ Top Comments:\n",
      "   - **Specs**\n",
      "\n",
      "* HP Dorado Micro ATX 8704\n",
      "* Core i5-10400F w/ Noctua NH-D9L Cooler\n",
      "* GeForce GTX 1660 Super \n",
      "* Corsair Vengeance LPX 32GB 2400 MHz \n",
      "* 512 GB PCIe NVMe M.2 Solid State \n",
      "* Almost 4 TB worth of additional HDD's \n",
      "* Cooler Master MWE 500 Bronze PSU (I think)\n",
      "* Additional Arctic 120mm case fans\n",
      "   - Hello Re_Set1991, and thank you for your submission to Gaming PC! If you are new please check out our rules over at the wiki [here](https://www.reddit.com/r/gamingpc/wiki/rules)!\n",
      "We have recently added the useful feature of Title Flair! You can set this manually by clicking Flair under your post once you have submitted your post, but if you missed it in the rules there is a much better way that will automatically flair your post!   \n",
      "\n",
      "To do this simply add what your post is about in brackets before your title. For example for a Build Log you can type [Build Log] before your post so that it looks like this; [Build Log]My new awesome build!, and the bot will automatically set your flair to Build Log! This works for Build Log, Build Showcase, News, Hardware News, Hardware Release, Discussion, and Miscellaneous!\n",
      "\n",
      "Also remember that this is a place for discussing and sharing our love of Gaming Computers! This is NOT the place for help building or determining what parts you should buy, that is better suited for /r/buildapc.  Troubleshooting questions should be directed to /r/techsupport. Thank you again!\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/gamingpc) if you have any questions or concerns.*\n",
      "   - Its glorious. Don't let anyone tell you different.\n",
      "   - love it, looks amazing\n",
      "   - Has a warm feeling to it. Enjoy. \n",
      "\n",
      "Seagate Technology | Official Forums Team\n",
      "\n",
      "üîπ 4. r/GamingPC let's talk Cases\n",
      "üîó URL: https://www.reddit.com/r/gamingpc/comments/l55mh/rgamingpc_lets_talk_cases/\n",
      "üí¨ Top Comments:\n",
      "   - Well currently the king of affordability and airflow is Cooler Master. There cases are typically more affordable while maintaining great airflow, achieving rave reviews. Most of them have great, large side panel fans for your GPUS.\n",
      "\n",
      "However the downside to Cooler Master is that the case itself is one ugly plastic SOB. Sorry to say. I'm speaking in terms of the HAF series which is their flagship case.\n",
      "\n",
      "Corsair is another highly rated case. They're the middle ground of affordability and airflow. I know that the Graphite series has great reviews, great looks, and is just an overall wonderful case. It has a side panel fan that is easily detachable for convenience and cooling. \n",
      "\n",
      "Antec is hardly recommended. I would say their only good series is anything 900+. The 300 is old and has poor cable management. About 6 months ago it was highly recommended off of sheer popularity. The 1200 series is a great case with great cable management, I can vouch that myself. In terms of price, it is again at the middle ground.\n",
      "\n",
      "I myself advocate for silent/performance/aesthetics. Fractal Design is my personal choice. It's affordable, extremely well built, durable (many hours in the car riding among horse poop), and just fricking gorgeous. There is sound dampening material that makes the case silent as well as anti-vibration installments of the HDD slots and stands.\n",
      "\n",
      "Let me tell you, I was skeptical about it not being cool, poor airflow with what appeared to be a restricted design. I was wrong. It is unbelievably cool. My CPU idles 23-26C, GPU idles around 29C. I have a Noctua, but before I did my stock fan had peaked 46-55C on max load (stock voltage/speed.) This beauty has great cable management in the back, quality painted interior, and side-panel fans for your needs. \n",
      "\n",
      "NZXT is another great alternative. There flagship case is the Phantom. It looks literally like a flagship. However, it does not have a side-panel fan. In terms of affordability, it's average. The Vulcan is a great affordable case with great airflow, not sure about 3xSLI support. \n",
      "\n",
      "There are other cases out there, but there not to great to recommend personally. Look at the reviews, key in to the design/aesthetics, and see if you're willing to spend that much.\n",
      "\n",
      "A good case for all that support will cost around $70-120. \n",
      "   - Nice post on r/BuildaPC [here](http://www.reddit.com/r/buildapc/comments/jqcs5/rbuildapc_we_need_to_talk_cases/)\n",
      "   - 385mm GPU's? that's almost 16 inches long.\n",
      "\n",
      "the [silverstone ft02](http://www.hardwaresecrets.com/article/SilverStone-Fortress-FT02-Case-Review/901/7) may be up your alley, though it has a 90-degree rotated motherboard design to help with cooling. 3 180mm fans blowing air through your gpu's/cpu = ICE COLD. if you're going to be spending that much on a case, you may as well go for the best. the tj07 is also great, if an aging design. \n",
      "\n",
      "if you want, you can also go for the coolermaster HAF X, though it doesn't hold a candle to the silverstone cases in terms of build quality. honestly though if you have that much money to blow i'd rather just get a corsair 800D or 650D and put in watercooling. \n",
      "   - Well, I have a Cooler Master Haf X, and I love it. It's huge, and awesome airflow.\n",
      "\n",
      "Some people say it's butt ugly, but I've grown fond of it. It's got the right looks for a battlestation, if I wanted a sleek and pretty design, I'd go Mac, haha.\n",
      "   - I'm gonna throw a lesser known brand out there but Azza makes some damned fine cases. I bought one on a whim for 70$'s and I love it. Azza Helios 910. Great airflow, nice looks, bottom mounted psu, easy to remove front panel covers, a 5.25\" to 3.5\" conversion piece, lots and lots of thumb screws, huge 200mm side fan. I'm running at 28 degrees on my motherboard sensor.\n",
      "\n",
      "My absolute only complaint is the space between the motherboard and side panel could be just a little bit bigger to allow for large cables. \n",
      "\n",
      "[Link](http://www.directcanada.com/products/?sku=27130AC0912&vpn=CSAZ-910&manufacture=AZZA%20Technology)\n",
      "\n",
      "üîπ 5. Here's my budget minimal PC! I tried my best to keep it clean, and am loving the new coolermaster mb311l.\n",
      "üîó URL: https://i.redd.it/btdytv54w6x41.jpg\n",
      "üí¨ Top Comments:\n",
      "   - Looks clean af, nice!\n",
      "   - Beautiful, simple, sleek and clean, great job, I think cooler master made a bad decision by leaving that huge gap up top, they could‚Äôve easily kept it smaller and make the case a bit smaller\n",
      "   - Black is very elegant in a build. Nicely done and game on. \n",
      "\n",
      "Seagate Technology | Official Forums Team\n",
      "   - Hello SvMazz, and thank you for your submission to Gaming PC! If you are new please check out our rules over at the wiki [here](https://www.reddit.com/r/gamingpc/wiki/rules)!\n",
      "We have recently added the useful feature of Title Flair! You can set this manually by clicking Flair under your post once you have submitted your post, but if you missed it in the rules there is a much better way that will automatically flair your post!   \n",
      "\n",
      "To do this simply add what your post is about in brackets before your title. For example for a Build Log you can type [Build Log] before your post so that it looks like this; [Build Log]My new awesome build!, and the bot will automatically set your flair to Build Log! This works for Build Log, Build Showcase, News, Hardware News, Hardware Release, Discussion, and Miscellaneous!\n",
      "\n",
      "Also remember that this is a place for discussing and sharing our love of Gaming Computers! This is NOT the place for help building or determining what parts you should buy, that is better suited for /r/buildapc.  Troubleshooting questions should be directed to /r/techsupport. Thank you again!\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/gamingpc) if you have any questions or concerns.*\n",
      "   - Specs:\n",
      "-cpu 1500x\n",
      "-gpu 1660 super\n",
      "-ram crucial ballistic 16gb 3200mhz\n",
      "-mobo Asus prime b450m\n",
      "-psu EVGA 500 watt bq\n",
      "-ssd 1tb crucial\n",
      "-case coolermaster mb311l\n",
      "\n",
      "üîπ 6. A good video card/psu for my budget gaming machine?\n",
      "üîó URL: https://www.reddit.com/r/gamingpc/comments/muha2/a_good_video_cardpsu_for_my_budget_gaming_machine/\n",
      "üí¨ Top Comments:\n",
      "   - For around $150, you should be able to nab yourself a Radeon HD 6850, or if you're lucky, a Radeon HD 6870 if one is on sale. Your PSU should be fine for your setup as long as it operates properly.\n",
      "   - For 100-150 you can get an hd6850 or possibly 6870 (there are a few that come to about 150 after rebate) if you want to go ATI.  The best current nvidia card you can find in that range is possibly a gtx 460 (possibly not the normal 1gb model, but maybe a 768mb or 1gb SE), there are a few right aroung 150 after rebate.  If you want to go cheaper and closer to 100 or under, the HD 5770/6770 is a great bang for the buck and still a decent low end gaming card.\n",
      "\n",
      "If it's a decent brand PSU, 480W should be fine for the cards in your budget.  I used one of the PSU calculators and put in your i3 and a 6870, and 6 fans, a cpu cooler, extra drives etc to give a bit of headroom and it came out to about 420W.  If you wanted a new psu, something like an antec NEO 520W should be plenty, or if you plan to upgrade further in the future you could go for a 600-650, which would be more than enough for anything you could possibly fit in that computer.\n",
      "   - Before you replace the PSU find out how good it actually is. Look at the base specs (most important: 12V lines, how many amps / watts can you pull from them?) and use a psu load calculator to find out how much you actually use. Only if that exceeds 90% of the 12V power (nearly all components nowadays use the 12V line) get a new PSU.\n",
      "   - At that price range I'd recommend an HD 6790. \n",
      "   - REDDIT IS A SHITTY CRIMINAL CORPORATION -- mass deleted all reddit content via https://redact.dev\n",
      "\n",
      "üîπ 7. The Best Budget Gaming PC! $150 (CS:GO/ Overwatch/ GTA V)\n",
      "üîó URL: https://www.youtube.com/watch?v=75f9OpGZ3aw&t=17s\n",
      "üí¨ Top Comments:\n",
      "\n",
      "üîπ 8. Settling a bet: the best pre-built gaming PC for 6k or under.\n",
      "üîó URL: https://www.reddit.com/r/gamingpc/comments/odsct/settling_a_bet_the_best_prebuilt_gaming_pc_for_6k/\n",
      "üí¨ Top Comments:\n",
      "   - Did your friend mean [this](http://www.hardcorecomputer.com/ProductConfigurator_productReactorX.aspx)? If so, you must be paying for $1000 in parts and what I'm guessing must be a $2800 case, at minimum config. In which case, I'd recommend your friend taking his $6000, flushing $4000 down the toilet and taking the remaining $2000 to build his own system that would smoke that reactor x by miles.\n",
      "   - Best for what? Gaming? What games? What resolution? Single, double, or triple monitors? Do peripherals count in the budget? Best is a terribly subjective word in terms of the PC world.\n",
      "   - A Murderbox will start @ $6000 - Not sure what the spec is at that price but they look stunning;\n",
      "\n",
      "http://www.million-dollar-pc.com/systems-2011/murderbox-mk2/murderbox-mk2.htm\n",
      "   - Updated the OP with more detail. Sorry for not being more specific in the first place.\n",
      "   - What monitor does he use specifically? Anyway I think the best pre-built is the origin's big O. It includes a xbox 360 built in so thats pretty cool and sli 580s. \n",
      "\n",
      "üîπ 9. Genesis : The budget gaming PC\n",
      "üîó URL: https://www.reddit.com/r/gamingpc/comments/23jpld/genesis_the_budget_gaming_pc/\n",
      "üí¨ Top Comments:\n",
      "   - This will play most games pretty decently. Congrats on your first build :-)\n",
      "   - yeah really solid build enjoy brother.\n",
      "   - Not a bad lil build spec wise, def needs some cable-fu tho. \n",
      "   - You can play genesis on a potato nowadays\n",
      "   - Thanks man!\n",
      "\n",
      "üîπ 10. Best Budget Gaming PC Build with Ryzen 3 in August 2017\n",
      "üîó URL: http://www.geekygamersclub.com/best-budget-gaming-pc-build-in-august-2017-with-ryzen-3/\n",
      "üí¨ Top Comments:\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import requests\n",
    "import spacy\n",
    "import json\n",
    "import re\n",
    "import ssl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Try to load Spacy model, use fallback if not available\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"[WARNING] Spacy model not found. Using basic keyword extraction.\")\n",
    "    nlp = None\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Fix SSL Issue (If network blocks SSL requests)\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Step 1: Optimize the query\n",
    "def optimize_query(query):\n",
    "    \"\"\"Optimizes user query using NLP or regex-based keyword extraction.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return \" \".join(keywords)\n",
    "    else:\n",
    "        # Fallback if Spacy is not installed\n",
    "        query = query.lower()\n",
    "        query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", query)  # Remove special characters\n",
    "        keywords = query.split()  # Basic word split\n",
    "        return \" \".join(keywords)\n",
    "\n",
    "# Step 2: Find the most relevant subreddit\n",
    "def find_best_subreddit(query):\n",
    "    \"\"\"Finds the most relevant subreddit based on a given query.\"\"\"\n",
    "    search_url = f\"https://www.reddit.com/search/?q={query}&type=sr\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        subreddit_links = soup.find_all('a', href=True)\n",
    "\n",
    "        for link in subreddit_links:\n",
    "            href = link['href']\n",
    "            if '/r/' in href and not href.startswith(\"https://www.reddit.com/user/\"):\n",
    "                return href.split('/r/')[1].split('/')[0]  # Extract subreddit name\n",
    "    return \"all\"  # Default to r/all if no specific subreddit is found\n",
    "\n",
    "# Step 3: Fetch posts and comments\n",
    "def fetch_reddit_posts(query):\n",
    "    \"\"\"Fetches top 10 posts from the best subreddit and stores them with comments in a JSON file.\"\"\"\n",
    "    optimized_query = optimize_query(query)\n",
    "    best_subreddit = find_best_subreddit(optimized_query)\n",
    "    \n",
    "    print(f\"\\nüîç Searching in subreddit: r/{best_subreddit} for '{optimized_query}'\\n\")\n",
    "    \n",
    "    try:\n",
    "        subreddit = reddit.subreddit(best_subreddit)\n",
    "        top_posts = subreddit.search(optimized_query, limit=10)\n",
    "\n",
    "        results = []\n",
    "        for post in top_posts:\n",
    "            post.comments.replace_more(limit=0)  # Load all top-level comments\n",
    "            comments = [comment.body for comment in post.comments.list()[:20]]  # Get first 20 comments\n",
    "\n",
    "            results.append({\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": comments\n",
    "            })\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open(\"reddit_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(\"‚úÖ Data saved to reddit_results.json\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching posts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Get user query and display results\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    posts = fetch_reddit_posts(user_query)\n",
    "\n",
    "    if posts:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nüîπ {idx+1}. {post['title']}\")\n",
    "            print(f\"üîó URL: {post['url']}\")\n",
    "            print(\"üí¨ Top Comments:\")\n",
    "            for comment in post['comments'][:5]:  # Show only first 5 comments in terminal\n",
    "                print(f\"   - {comment}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No relevant posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "857de4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: spacy in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw requests spacy beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4753b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.4/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 2.9/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 3.9/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f68ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA-enabled GPU for processing.\n",
      "\n",
      "üîç Searching in subreddit: r/de for ''\n",
      "\n",
      "‚úÖ Data saved to reddit_results.json\n",
      "‚ö†Ô∏è No relevant posts found.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import requests\n",
    "import spacy\n",
    "import re\n",
    "import ssl\n",
    "import json\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA-enabled GPU for processing.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available, using CPU.\")\n",
    "\n",
    "# Try to load Spacy model, fallback to regex if unavailable\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"[WARNING] Spacy model not found. Using basic regex-based optimization.\")\n",
    "    nlp = None\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"As44RYqjOK4m9FJ53EwC-g\",\n",
    "    client_secret=\"9jscdaZAODphthPzuVumkAgvH5EYJw\",\n",
    "    user_agent=\"Narative/0.1 by your_reddit_username\"\n",
    ")\n",
    "\n",
    "# Fix SSL Issue\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Step 1: Optimize the query\n",
    "def optimize_query(query):\n",
    "    \"\"\"Optimizes user query using NLP or regex-based keyword extraction.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "        return \" \".join(keywords)\n",
    "    else:\n",
    "        # Fallback if Spacy is not installed\n",
    "        query = query.lower()\n",
    "        query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", query)  # Remove special characters\n",
    "        keywords = query.split()  # Basic word split\n",
    "        return \" \".join(keywords)\n",
    "\n",
    "# Step 2: Find the most relevant subreddit\n",
    "def find_best_subreddit(query):\n",
    "    \"\"\"Finds the most relevant subreddit based on a given query.\"\"\"\n",
    "    search_url = f\"https://www.reddit.com/search/?q={query}&type=sr\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        subreddit_links = soup.find_all('a', href=True)\n",
    "        for link in subreddit_links:\n",
    "            href = link['href']\n",
    "            if '/r/' in href and not href.startswith(\"https://www.reddit.com/user/\"):\n",
    "                return href.split('/r/')[1].split('/')[0]  # Extract subreddit name\n",
    "    return \"all\"  # Default to r/all if no specific subreddit is found\n",
    "\n",
    "# Step 3: Fetch posts from the best subreddit\n",
    "def fetch_reddit_posts(query):\n",
    "    \"\"\"Fetches top 10 posts from the best subreddit for the query and stores in a JSON file.\"\"\"\n",
    "    optimized_query = optimize_query(query)\n",
    "    best_subreddit = find_best_subreddit(optimized_query)\n",
    "    print(f\"\\nüîç Searching in subreddit: r/{best_subreddit} for '{optimized_query}'\\n\")\n",
    "    try:\n",
    "        subreddit = reddit.subreddit(best_subreddit)\n",
    "        top_posts = subreddit.search(optimized_query, limit=50)\n",
    "        results = []\n",
    "        for post in top_posts:\n",
    "            post.comments.replace_more(limit=0)  # Load all top-level comments\n",
    "            comments = [comment.body for comment in post.comments[:50]]  # Get first 50 comments\n",
    "            results.append({\n",
    "                \"title\": post.title,\n",
    "                \"url\": post.url,\n",
    "                \"comments\": comments\n",
    "            })\n",
    "        # Save results to JSON file\n",
    "        with open(\"reddit_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        print(\"‚úÖ Data saved to reddit_results.json\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching posts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Get user query and display results\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    posts = fetch_reddit_posts(user_query)\n",
    "    if posts:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nüîπ {idx+1}. {post['title']}\")\n",
    "            print(f\"üîó URL: {post['url']}\")\n",
    "            print(\"üí¨ Top Comments:\")\n",
    "            for comment in post['comments'][:5]:  # Show only first 5 comments in the terminal\n",
    "                print(f\"   - {comment}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No relevant posts found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abd828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 200, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 200, but your input_length is only 170. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\n",
      "Your max_length is set to 200, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 200, but your input_length is only 121. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 200, but your input_length is only 172. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 200, but your input_length is only 152. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=76)\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Your max_length is set to 200, but your input_length is only 199. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n",
      "Your max_length is set to 200, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 200, but your input_length is only 174. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 200, but your input_length is only 178. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 200, but your input_length is only 166. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=83)\n",
      "Your max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\n",
      "Your max_length is set to 200, but your input_length is only 192. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 200, but your input_length is only 191. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 200, but your input_length is only 158. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=79)\n",
      "Your max_length is set to 200, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 200, but your input_length is only 190. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 200, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n",
      "Your max_length is set to 200, but your input_length is only 184. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=92)\n",
      "Your max_length is set to 200, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n",
      "Your max_length is set to 200, but your input_length is only 160. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=80)\n",
      "Your max_length is set to 200, but your input_length is only 194. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n",
      "Your max_length is set to 200, but your input_length is only 195. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n",
      "Your max_length is set to 200, but your input_length is only 115. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\n",
      "Your max_length is set to 200, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 200, but your input_length is only 70. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 200, but your input_length is only 117. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n",
      "Your max_length is set to 200, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 200, but your input_length is only 126. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 200, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 200, but your input_length is only 199. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n",
      "Your max_length is set to 200, but your input_length is only 76. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 200, but your input_length is only 193. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 200, but your input_length is only 188. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=94)\n",
      "Your max_length is set to 200, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 200, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 200, but your input_length is only 128. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 200, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 200, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 200, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 200, but your input_length is only 163. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 200, but your input_length is only 60. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 200, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 200, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 200, but your input_length is only 81. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 200, but your input_length is only 186. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 200, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 200, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final summarized results saved to reddit_summary.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load NLP model for topic detection\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    nlp = None\n",
    "\n",
    "# Define a helper function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s\\.\\,]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# Extract key topics from text\n",
    "def extract_topics(text, top_n=5):\n",
    "    if nlp:\n",
    "        doc = nlp(text)\n",
    "        words = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "        return [word[0] for word in Counter(words).most_common(top_n)]\n",
    "    return []  # Fallback if Spacy is unavailable\n",
    "\n",
    "# Function to process and extract key content from JSON data\n",
    "def preprocess_data(data):\n",
    "    processed_text = []\n",
    "    for entry in data:\n",
    "        key_topics = extract_topics(entry[\"title\"])  # Extract key topics from the title\n",
    "        text_chunk = f\"Title: {clean_text(entry['title'])}. \"\n",
    "        insightful_comments = []\n",
    "        for comment in entry[\"comments\"]:\n",
    "            comment_lower = comment.lower().strip()\n",
    "            if comment_lower in [\"[deleted]\", \"[removed]\", \"thanks\", \"lol\", \"nice\"]:\n",
    "                continue  # Skip irrelevant comments\n",
    "            insightful_comments.append(clean_text(comment))\n",
    "        text_chunk += \" \".join(insightful_comments[:5])  # Take top 5 meaningful comments\n",
    "        processed_text.append((text_chunk, key_topics))\n",
    "    return processed_text\n",
    "\n",
    "# Splitting text into smaller chunks\n",
    "def chunk_text(text, max_chunk_size=1024):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        current_length += len(word) + 1  # +1 for space\n",
    "        if current_length > max_chunk_size:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = len(word)\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Summarization function\n",
    "def summarize_text(text_chunks, summarizer, max_length=200, min_length=50):\n",
    "    summaries = []\n",
    "    for chunk in text_chunks:\n",
    "        summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        summaries.append(summary[0][\"summary_text\"])\n",
    "    return summaries\n",
    "\n",
    "# Load Reddit results\n",
    "data_file = \"reddit_results.json\"\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Pre-process text data\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Generate summaries with key topics\n",
    "final_summaries = []\n",
    "for text, topics in processed_data:\n",
    "    chunks = chunk_text(text)\n",
    "    chunk_summaries = summarize_text(chunks, summarizer)\n",
    "    full_summary = \" \".join(chunk_summaries)\n",
    "    if topics:\n",
    "        full_summary = f\"Key Topics: {', '.join(topics)}. {full_summary}\"\n",
    "    final_summaries.append(full_summary)\n",
    "\n",
    "# Save final summaries\n",
    "with open(\"reddit_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_summaries, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Final summarized results saved to reddit_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755e00a-121e-429d-89ea-ff8fb2a64090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79d8d47-2bf1-4236-9e56-5a986477908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary: I feel Nirbhaya rapist were given capital punishment and matter closed,though it still took long,only because they were nobodies. Government controls the basic things like construction dust, seal the roads and regulate industries we can cut down pollution by 5070. Casteism and pollution, two of the biggest problems of India.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def summarize_key_points(filename):\n",
    "    import json\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    combined_text = \" \".join(data)\n",
    "\n",
    "    # Limit the input text to 1024 tokens (approx. 4000 characters)\n",
    "    combined_text = combined_text[:4000]  # Adjust if needed\n",
    "\n",
    "    # Initialize summarization pipeline\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=-1)\n",
    "\n",
    "    # Summarize in smaller chunks if text is too long\n",
    "    summary = summarizer(combined_text, max_length=150, min_length=50, do_sample=False)\n",
    "\n",
    "    return summary[0][\"summary_text\"]\n",
    "\n",
    "# Example usage\n",
    "summary_result = summarize_key_points(\"reddit_summary.json\")\n",
    "print(\"Final Summary:\", summary_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fece04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
