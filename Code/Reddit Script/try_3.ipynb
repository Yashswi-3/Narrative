{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title  \\\n",
      "0   Megathread: Joe Biden Projected to Defeat Pres...   \n",
      "1   ðŸ“£ I want to debunk Reddit's claims, and talk a...   \n",
      "2   Megathread: Joseph R. Biden Sworn in as the 46...   \n",
      "3   SOPA, PIPA, CISPA, ACTA, TPP, ITU, CISPA again...   \n",
      "4   Megathread: Twitter Permanently Suspends @real...   \n",
      "..                                                ...   \n",
      "95  X caught blocking links to NPR, claiming the n...   \n",
      "96  I took my cat for x-rays and found out her pre...   \n",
      "97  GameStop cannot enact a Share Recall. But I fo...   \n",
      "98  [OC] we always ask \"what lineup would you use ...   \n",
      "99         TIFU By Becoming a Suspected Serial Killer   \n",
      "\n",
      "                                         Body/Content  Post ID   Subreddit  \\\n",
      "0   Former Vice President Joseph Biden has secured...   jptq5n    politics   \n",
      "1   I wanted to address Reddit's continued, provab...  14dkqrw   apolloapp   \n",
      "2   Joe Biden became the 46th President of the Uni...   l1dj7s    politics   \n",
      "3   Via the wonderful /u/vriska1\\n\\nIf you want to...   6bytpx  technology   \n",
      "4   Twitter has announced a permanent suspension o...   kteyie    politics   \n",
      "..                                                ...      ...         ...   \n",
      "95                                                     1f4con6  technology   \n",
      "96  This picture was taken when I met my sweet Leo...  1c6atmm        cats   \n",
      "97  # 0. Preface\\n\\n**TLDR:** For the last 84 year...   xpcxc1  Superstonk   \n",
      "98  During the offseason, we tend to float silly h...   d3p22l         nba   \n",
      "99  \\nI used to have a pretty big Internet footpri...   nhcqvn        tifu   \n",
      "\n",
      "              Date/Time  Upvotes  Downvotes  Number of Comments  \\\n",
      "0   2020-11-07 16:28:04   214316          0               81425   \n",
      "1   2023-06-19 17:23:42   134003          0                5455   \n",
      "2   2021-01-20 17:14:52   112130          0               27839   \n",
      "3   2017-05-18 20:18:08   104106          0                3831   \n",
      "4   2021-01-08 23:43:38    97192          0               36530   \n",
      "..                  ...      ...        ...                 ...   \n",
      "95  2024-08-29 20:30:48    11872          0                 276   \n",
      "96  2024-04-17 14:08:09    11863          0                 561   \n",
      "97  2022-09-27 10:28:17    11848          0                 600   \n",
      "98  2019-09-13 13:11:48    11792          0                 374   \n",
      "99  2021-05-20 21:59:32    11724          0                 716   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://www.reddit.com/r/politics/comments/jpt...  \n",
      "1   https://www.reddit.com/r/apolloapp/comments/14...  \n",
      "2   https://www.reddit.com/r/politics/comments/l1d...  \n",
      "3   https://www.reddit.com/r/technology/comments/6...  \n",
      "4   https://www.reddit.com/r/politics/comments/kte...  \n",
      "..                                                ...  \n",
      "95  https://techcrunch.com/2024/08/29/x-caught-blo...  \n",
      "96               https://i.redd.it/2yo9z1hjr1vc1.jpeg  \n",
      "97  https://www.reddit.com/r/Superstonk/comments/x...  \n",
      "98  https://www.reddit.com/r/nba/comments/d3p22l/o...  \n",
      "99  https://www.reddit.com/r/tifu/comments/nhcqvn/...  \n",
      "\n",
      "[100 rows x 9 columns]\n",
      "Data saved to reddit_top_posts_tech news.json\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Create a Reddit instance (Replace 'your_client_id', 'your_client_secret', and 'your_user_agent' with your credentials)\n",
    "reddit = praw.Reddit(client_id='pC9dZB_wqZ9Son7HPJUc8w',\n",
    "                     client_secret='4hpR2C7Fpov0QGM7g5QNKJqsN0SmRA',\n",
    "                     user_agent='narative by /u/No_Type7179')\n",
    "\n",
    "# Function to fetch top 10 posts based on search query\n",
    "def fetch_top_posts(search_query, subreddit_name='all', limit=100):\n",
    "    # Search for the top posts in the specified subreddit based on the query\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    top_posts = subreddit.search(search_query, sort='top', limit=limit)\n",
    "\n",
    "    # Create an empty list to store post data\n",
    "    post_data = []\n",
    "\n",
    "    # Loop through the top posts and extract details\n",
    "    for post in top_posts:\n",
    "        # Convert UTC timestamp to human-readable date and time\n",
    "        post_datetime = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Calculate downvotes (upvotes - score)\n",
    "        upvotes = post.ups\n",
    "        downvotes = upvotes - post.score\n",
    "        \n",
    "        # Append post details to the list\n",
    "        post_data.append({\n",
    "            'Title': post.title,\n",
    "            'Body/Content': post.selftext,\n",
    "            'Post ID': post.id,\n",
    "            'Subreddit': post.subreddit.display_name,\n",
    "            'Date/Time': post_datetime,\n",
    "            'Upvotes': upvotes,\n",
    "            'Downvotes': downvotes,\n",
    "            'Number of Comments': post.num_comments,\n",
    "            'Link': post.url  # Add the link to the post\n",
    "        })\n",
    "    \n",
    "    # Store data in a pandas DataFrame (optional)\n",
    "    df = pd.DataFrame(post_data)\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    json_filename = f'reddit_top_posts_{search_query}.json'\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(post_data, f, indent=4)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Indicate where the JSON file is saved\n",
    "    print(f\"Data saved to {json_filename}\")\n",
    "\n",
    "# Input: search query and subreddit (optional, defaults to 'all')\n",
    "search_query = input(\"Enter the topic you want to search for: \")\n",
    "subreddit_name = input(\"Enter the subreddit to search in (default is 'all'): \") or 'all'\n",
    "\n",
    "# Fetch and store top 10 posts based on the search query\n",
    "fetch_top_posts(search_query, subreddit_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
